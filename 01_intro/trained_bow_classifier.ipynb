{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is from https://github.com/neubig/anlp-code* by Graham Neubig\n",
    "\n",
    "We added additional printing of feature weights in the Error Analysis section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Sentiment Classifier\n",
    "\n",
    "This is a notebook for [LUH Advanced NLP](https://sites.google.com/view/jen-web/sose-2025) that trains a sentiment classifier based on data. Specifically, it uses a bag-of-words to extract features, and the structured perceptron algorithm to train the classifier.\n",
    "\n",
    "It will take in a text `X` and return a `label` of \"1\" if the sentiment of the text is positive, \"-1\" if the sentiment of the text is negative, and \"0\" if the sentiment of the text is neutral. You can test the accuracy of your classifier on the [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html) by running the notebook all the way to end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setup code, do imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Feature extraction code, how do we get the features we use in training? By default we just use every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x: str) -> dict[str, float]:\n",
    "    features = {}\n",
    "    x_split = x.split(' ')\n",
    "    for x in x_split:\n",
    "        features[x] = features.get(x, 0) + 1.0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, initialize the feature weights to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_weights = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n",
    "\n",
    "Read in the data from the training and dev (or finally test) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            x_data.append(text)\n",
    "            y_data.append(int(label))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_xy_data('./data/train.txt')\n",
    "x_dev, y_dev = read_xy_data('./data/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Code\n",
    "\n",
    "How we run the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(features: dict[str, float]) -> int:\n",
    "    score = 0\n",
    "    for feat_name, feat_value in features.items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Learn the weights of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 8544/8544 [00:00<00:00, 203393.67it/s]\n",
      "Epoch 2: 100%|██████████| 8544/8544 [00:00<00:00, 203427.15it/s]\n",
      "Epoch 3: 100%|██████████| 8544/8544 [00:00<00:00, 244130.32it/s]\n",
      "Epoch 4: 100%|██████████| 8544/8544 [00:00<00:00, 251294.71it/s]\n",
      "Epoch 5: 100%|██████████| 8544/8544 [00:00<00:00, 258920.37it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    # Shuffle the order of the data\n",
    "    data_ids = list(range(len(x_train)))\n",
    "    random.shuffle(data_ids)\n",
    "    # Run over all data points\n",
    "    for data_id in tqdm.tqdm(data_ids, desc=f'Epoch {epoch}'):\n",
    "        x = x_train[data_id]\n",
    "        y = y_train[data_id]\n",
    "        # We will skip neutral examples\n",
    "        if y == 0:    \n",
    "            continue\n",
    "        # Make a prediction\n",
    "        features = extract_features(x)\n",
    "        predicted_y = run_classifier(features)\n",
    "        # Update the weights if the prediction is wrong\n",
    "        if predicted_y != y:\n",
    "            for feature in features:\n",
    "                feature_weights[feature] = feature_weights.get(feature, 0) + y * features[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Code\n",
    "\n",
    "How we evaluate the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        y_pred = run_classifier(extract_features(x))\n",
    "        total_number += 1\n",
    "        if y == y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 444, 0: 229, -1: 428}\n"
     ]
    }
   ],
   "source": [
    "label_count = {}\n",
    "for y in y_dev:\n",
    "    if y not in label_count:\n",
    "        label_count[y] = 0\n",
    "    label_count[y] += 1\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.766619850187266\n",
      "Dev/test accuracy: 0.5821980018165305\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(x_train, y_train)\n",
    "test_accuracy = calculate_accuracy(x_dev, y_dev)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the feature weights and print the top 10 and bottom 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "An important part of improving any system is figuring out where it goes wrong. The following two functions allow you to randomly observe some mistaken examples, which may help you improve the classifier. Feel free to write more sophisticated methods for error analysis as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_contributions(features):\n",
    "    output = {}\n",
    "    for feat_name, feat_value in features.items():\n",
    "        output[feat_name] = feat_value * feature_weights.get(feat_name, 0)\n",
    "    return output\n",
    "\n",
    "def find_errors(x_data, y_data):\n",
    "    error_ids = []\n",
    "    y_preds = []\n",
    "    id2contributions = {}\n",
    "    for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "        features = extract_features(x)\n",
    "        y_preds.append(run_classifier(features))\n",
    "        if y != y_preds[-1]:\n",
    "            error_ids.append(i)\n",
    "            id2contributions[i] = get_feature_contributions(features)\n",
    "    for _ in range(5):\n",
    "        my_id = random.choice(error_ids)\n",
    "        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]\n",
    "\n",
    "        print(f'{x}\\ntrue label: {y}\\npredicted label: {y_pred}')\n",
    "        contributions = sorted(id2contributions[my_id].items(), key=lambda x: -x[1])\n",
    "        for feat_name, contribution in contributions:\n",
    "            print(f'Feature: {feat_name} ({contribution})')\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite the evocative aesthetics evincing the hollow state of modern love life , the film never percolates beyond a monotonous whine .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "Feature: love (8.0)\n",
      "Feature: evocative (5.0)\n",
      "Feature: the (3.0)\n",
      "Feature: modern (3.0)\n",
      "Feature: film (3.0)\n",
      "Feature: aesthetics (1.0)\n",
      "Feature: life (1.0)\n",
      "Feature: evincing (0.0)\n",
      "Feature: state (0.0)\n",
      "Feature: never (0.0)\n",
      "Feature: percolates (0.0)\n",
      "Feature: a (0.0)\n",
      "Feature: . (0.0)\n",
      "Feature: Despite (-1.0)\n",
      "Feature: of (-1.0)\n",
      "Feature: , (-1.0)\n",
      "Feature: whine (-1.0)\n",
      "Feature: hollow (-4.0)\n",
      "Feature: beyond (-4.0)\n",
      "Feature: monotonous (-4.0)\n",
      "\n",
      "The primitive force of this film seems to bubble up from the vast collective memory of the combatants .\n",
      "true label: 1\n",
      "predicted label: -1\n",
      "Feature: force (6.0)\n",
      "Feature: film (3.0)\n",
      "Feature: The (2.0)\n",
      "Feature: the (2.0)\n",
      "Feature: from (1.0)\n",
      "Feature: primitive (0.0)\n",
      "Feature: this (0.0)\n",
      "Feature: bubble (0.0)\n",
      "Feature: combatants (0.0)\n",
      "Feature: . (0.0)\n",
      "Feature: up (-1.0)\n",
      "Feature: collective (-1.0)\n",
      "Feature: of (-2.0)\n",
      "Feature: seems (-3.0)\n",
      "Feature: vast (-3.0)\n",
      "Feature: memory (-3.0)\n",
      "Feature: to (-4.0)\n",
      "\n",
      "The messages of compassion and mercy are clearly , squarely and specifically expounded via computer animated Old Testament tale of Jonah and the Whale .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "Feature: and (6.0)\n",
      "Feature: via (4.0)\n",
      "Feature: animated (4.0)\n",
      "Feature: messages (3.0)\n",
      "Feature: tale (3.0)\n",
      "Feature: The (2.0)\n",
      "Feature: mercy (2.0)\n",
      "Feature: Jonah (2.0)\n",
      "Feature: specifically (1.0)\n",
      "Feature: the (1.0)\n",
      "Feature: expounded (0.0)\n",
      "Feature: Whale (0.0)\n",
      "Feature: . (0.0)\n",
      "Feature: , (-1.0)\n",
      "Feature: squarely (-1.0)\n",
      "Feature: Testament (-1.0)\n",
      "Feature: of (-2.0)\n",
      "Feature: compassion (-2.0)\n",
      "Feature: are (-2.0)\n",
      "Feature: Old (-2.0)\n",
      "Feature: computer (-3.0)\n",
      "Feature: clearly (-4.0)\n",
      "\n",
      "Fresnadillo 's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that wo n't go away .\n",
      "true label: 1\n",
      "predicted label: -1\n",
      "Feature: wo (6.0)\n",
      "Feature: way (5.0)\n",
      "Feature: you (4.0)\n",
      "Feature: images (3.0)\n",
      "Feature: that (3.0)\n",
      "Feature: dark (2.0)\n",
      "Feature: and (2.0)\n",
      "Feature: subconscious (2.0)\n",
      "Feature: go (2.0)\n",
      "Feature: the (1.0)\n",
      "Feature: Fresnadillo (0.0)\n",
      "Feature: 's (0.0)\n",
      "Feature: jolting (0.0)\n",
      "Feature: a (0.0)\n",
      "Feature: plying (0.0)\n",
      "Feature: into (0.0)\n",
      "Feature: nightmare (0.0)\n",
      "Feature: . (0.0)\n",
      "Feature: of (-1.0)\n",
      "Feature: away (-1.0)\n",
      "Feature: your (-2.0)\n",
      "Feature: like (-2.0)\n",
      "Feature: have (-3.0)\n",
      "Feature: ago (-4.0)\n",
      "Feature: had (-6.0)\n",
      "Feature: week (-6.0)\n",
      "Feature: n't (-9.0)\n",
      "\n",
      "But its awkward structure keeps breaking the spell .\n",
      "true label: 0\n",
      "predicted label: -1\n",
      "Feature: spell (4.0)\n",
      "Feature: breaking (2.0)\n",
      "Feature: keeps (1.0)\n",
      "Feature: the (1.0)\n",
      "Feature: . (0.0)\n",
      "Feature: its (-1.0)\n",
      "Feature: structure (-3.0)\n",
      "Feature: But (-4.0)\n",
      "Feature: awkward (-6.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_errors(x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize feature weights\n",
    "\n",
    "We can inspect the weights that were learned for various features. Below we show the largest, smallest, and randomly selected feature weights. Inspecting them may give insight into the learned classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k\n",
      "('solid', 13.0)\n",
      "('remarkable', 13.0)\n",
      "('appealing', 12.0)\n",
      "('powerful', 12.0)\n",
      "('rare', 11.0)\n",
      "('sweet', 11.0)\n",
      "('terrific', 11.0)\n",
      "('portrait', 11.0)\n",
      "('refreshing', 11.0)\n",
      "('brilliant', 10.0)\n",
      "('hilarious', 10.0)\n",
      "('beautifully', 10.0)\n",
      "('somewhat', 10.0)\n",
      "('going', 9.0)\n",
      "('human', 9.0)\n",
      "('wonderful', 9.0)\n",
      "('eyes', 9.0)\n",
      "('fun', 9.0)\n",
      "('works', 9.0)\n",
      "('deeply', 9.0)\n",
      "('perfectly', 9.0)\n",
      "('wonderfully', 9.0)\n",
      "('sharp', 9.0)\n",
      "('entertaining', 9.0)\n",
      "('follow', 9.0)\n",
      "\n",
      "Bottom-k\n",
      "('stupid', -14.0)\n",
      "('were', -14.0)\n",
      "('worst', -13.0)\n",
      "('suffers', -13.0)\n",
      "('TV', -12.0)\n",
      "('repetitive', -12.0)\n",
      "('mess', -12.0)\n",
      "('left', -11.0)\n",
      "('idea', -11.0)\n",
      "('Lawrence', -11.0)\n",
      "('pretentious', -11.0)\n",
      "('lousy', -11.0)\n",
      "('none', -11.0)\n",
      "('contrived', -10.0)\n",
      "('Unfortunately', -10.0)\n",
      "('lacking', -10.0)\n",
      "('flat', -10.0)\n",
      "('dull', -10.0)\n",
      "('Feels', -10.0)\n",
      "('Sheridan', -10.0)\n",
      "('instead', -10.0)\n",
      "('violence', -10.0)\n",
      "('scene', -10.0)\n",
      "(\"n't\", -9.0)\n",
      "('bore', -9.0)\n",
      "\n",
      "Random k\n",
      "('documentarian', 1.0)\n",
      "('Beavis', 1.0)\n",
      "('happened', -3.0)\n",
      "('ticket', 1.0)\n",
      "('Exactly', 1.0)\n",
      "('assign', -3.0)\n",
      "('provide', -1.0)\n",
      "('Motown', 1.0)\n",
      "('funnybone', 1.0)\n",
      "('interested', 0.0)\n",
      "('bling-bling', -1.0)\n",
      "('director', -1.0)\n",
      "('Q', 1.0)\n",
      "('fish', -4.0)\n",
      "('even-handedness', -2.0)\n",
      "('tabloid', -3.0)\n",
      "('flowers', -2.0)\n",
      "('monologue', 1.0)\n",
      "('Dey', 1.0)\n",
      "('smallness', 1.0)\n",
      "('Dash', -2.0)\n",
      "('sneeze', 3.0)\n",
      "('slickest', 1.0)\n",
      "('really', -5.0)\n",
      "('brush', 1.0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "k = 25\n",
    "topk_features = sorted(feature_weights.items(), key=lambda x: -x[1])[:k]\n",
    "bottomk_features = sorted(feature_weights.items(), key=lambda x: x[1])[:k]\n",
    "randomk_features = random.sample(list(feature_weights.items()), k)\n",
    "\n",
    "print(\"Top-k\")\n",
    "for feature in topk_features:\n",
    "    print(feature)\n",
    "\n",
    "print(\"\\nBottom-k\")\n",
    "for feature in bottomk_features:\n",
    "    print(feature)\n",
    "\n",
    "print(\"\\nRandom k\")\n",
    "for feature in randomk_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
